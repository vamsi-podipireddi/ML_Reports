{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e288e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea2b9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RegressionEvaluation\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d501f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_predictions.csv\")\n",
    "test_data = pd.read_csv(\"test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c623f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = spark.createDataFrame(train_data)\n",
    "test_df = spark.createDataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pandas_df = train_df.select(\"prediction\", \"actual\").limit(100000).toPandas()\n",
    "test_pandas_df = test_df.select(\"prediction\", \"actual\").limit(100000).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa92e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def actual_vs_predicted(train_df, test_df):\n",
    "    # 1) global data extents for y=x\n",
    "    all_vals = pd.concat([\n",
    "        train_df[\"actual\"], train_df[\"prediction\"],\n",
    "        test_df[\"actual\"],  test_df[\"prediction\"]\n",
    "    ])\n",
    "    lo, hi = all_vals.min(), all_vals.max()\n",
    "\n",
    "    # 2) compute best–fit coefficients\n",
    "    m_tr, b_tr = np.polyfit(train_df[\"actual\"], train_df[\"prediction\"], 1)\n",
    "    m_te, b_te = np.polyfit(test_df[\"actual\"],  test_df[\"prediction\"],  1)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "\n",
    "\n",
    "    # 4) scatter points\n",
    "    fig.add_trace(go.Scattergl(\n",
    "        x=train_df[\"actual\"], y=train_df[\"prediction\"],\n",
    "        mode=\"markers\", name=\"Train\",\n",
    "        marker=dict(opacity=0.7),\n",
    "        line=dict(color=\"royalblue\", width=2),\n",
    "    ))\n",
    "    fig.add_trace(go.Scattergl(\n",
    "        x=test_df[\"actual\"], y=test_df[\"prediction\"],\n",
    "        mode=\"markers\", name=\"Test\",\n",
    "        marker=dict(symbol=\"x\", opacity=0.7),\n",
    "        line=dict(color=\"crimson\", width=2),\n",
    "        \n",
    "    ))\n",
    "\n",
    "    # 3) y = x reference line (legend-only)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[lo, hi], y=[lo, hi],\n",
    "        mode=\"lines\",\n",
    "        name=\"Perfect fit\",\n",
    "        line=dict(color=\"black\", dash=\"dash\"),\n",
    "        visible=\"legendonly\"\n",
    "    ))\n",
    "\n",
    "    # 5) train best–fit line\n",
    "    x_tr = [train_df[\"actual\"].min(), train_df[\"actual\"].max()]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_tr,\n",
    "        y=[m_tr*x_tr[0] + b_tr, m_tr*x_tr[1] + b_tr],\n",
    "        mode=\"lines\",\n",
    "        name=\"Train fit\",\n",
    "        line=dict(color=\"royalblue\", width=2),\n",
    "        visible=\"legendonly\"\n",
    "    ))\n",
    "\n",
    "    # 6) test best–fit line\n",
    "    x_te = [test_df[\"actual\"].min(), test_df[\"actual\"].max()]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_te,\n",
    "        y=[m_te*x_te[0] + b_te, m_te*x_te[1] + b_te],\n",
    "        mode=\"lines\",\n",
    "        name=\"Test fit\",\n",
    "        line=dict(color=\"crimson\", width=2),\n",
    "        visible=\"legendonly\"\n",
    "    ))\n",
    "\n",
    "    # 7) add equations box at top-left\n",
    "    eq_text = (\n",
    "        f\"<b>Train fit</b>: y = {m_tr:.2f}x + {b_tr:.2f}<br>\"\n",
    "        f\"<b>Test fit</b>: y = {m_te:.2f}x + {b_te:.2f}\"\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=0, y=1, xref=\"paper\", yref=\"paper\",\n",
    "        text=eq_text,\n",
    "        showarrow=False,\n",
    "        align=\"left\",\n",
    "        bgcolor=\"white\",\n",
    "        bordercolor=\"black\",\n",
    "        borderwidth=1,\n",
    "        xanchor=\"left\",\n",
    "        yanchor=\"top\"\n",
    "    )\n",
    "\n",
    "    # 8) styling\n",
    "    fig.update_layout(\n",
    "        title=dict(text=\"Actual vs. Predicted\", x=0.5),\n",
    "        legend=dict(orientation=\"h\", x=0.5, y=-0.15, xanchor=\"center\", yanchor=\"top\"),\n",
    "        xaxis_title=\"Actual\",\n",
    "        yaxis_title=\"Predicted\",\n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\",\n",
    "        width=700, height=500,\n",
    "        margin=dict(t=80, b=60)\n",
    "    )\n",
    "    fig.update_xaxes(showgrid=True, gridcolor=\"lightgrey\", zeroline=False, showline=False)\n",
    "    fig.update_yaxes(showgrid=True, gridcolor=\"lightgrey\", zeroline=False, showline=False)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee59a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_vs_predicted(train_pandas_df, test_pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca687ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def residuals_vs_predicted(train_df, test_df):\n",
    "    # compute residuals\n",
    "    train = train_df.copy()\n",
    "    train[\"residual\"] = train[\"actual\"] - train[\"prediction\"]\n",
    "    test = test_df.copy()\n",
    "    test[\"residual\"] = test[\"actual\"] - test[\"prediction\"]\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # train residuals\n",
    "    fig.add_trace(go.Scattergl(\n",
    "        x=train[\"prediction\"],\n",
    "        y=train[\"residual\"],\n",
    "        mode=\"markers\",\n",
    "        name=\"Train\",\n",
    "        line=dict(color=\"royalblue\", width=2),\n",
    "        marker=dict(opacity=0.8)\n",
    "    ))\n",
    "\n",
    "    # test residuals\n",
    "    fig.add_trace(go.Scattergl(\n",
    "        x=test[\"prediction\"],\n",
    "        y=test[\"residual\"],\n",
    "        mode=\"markers\",\n",
    "        name=\"Test\",\n",
    "        line=dict(color=\"crimson\", width=2),\n",
    "        marker=dict(symbol=\"x\", opacity=0.8)\n",
    "    ))\n",
    "\n",
    "    # horizontal zero‐residual line spanning full plot width\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        xref=\"paper\", yref=\"y\",\n",
    "        x0=0, x1=1,\n",
    "        y0=0, y1=0,\n",
    "        line=dict(color=\"grey\", dash=\"dash\")\n",
    "    )\n",
    "\n",
    "    # layout: centered title, bottom legend, white bg, grey grid\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=\"Residuals vs. Predicted\",\n",
    "            x=0.5, xanchor=\"center\"\n",
    "        ),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            x=0.5, xanchor=\"center\",\n",
    "            y=-0.15, yanchor=\"top\"\n",
    "        ),\n",
    "        xaxis_title=\"Predicted\",\n",
    "        yaxis_title=\"Residual\",\n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\",\n",
    "        width=700,\n",
    "        height=500,\n",
    "        margin=dict(t=80, b=60)\n",
    "    )\n",
    "\n",
    "    # grey gridlines\n",
    "    fig.update_xaxes(showgrid=True, gridcolor=\"lightgrey\", zeroline=False, showline=False)\n",
    "    fig.update_yaxes(showgrid=True, gridcolor=\"lightgrey\", zeroline=False, showline=False)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e82bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_vs_predicted(train_pandas_df, test_pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6a1557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "def residuals_qq_plot(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Creates a Normal Q–Q plot of residuals for train and test sets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_df : pandas.DataFrame\n",
    "        DataFrame containing 'actual' and 'prediction' columns for training set.\n",
    "    test_df : pandas.DataFrame\n",
    "        DataFrame containing 'actual' and 'prediction' columns for test set.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fig : plotly.graph_objects.Figure\n",
    "    \"\"\"\n",
    "    # 1) compute residuals\n",
    "    train_res = train_df[\"actual\"] - train_df[\"prediction\"]\n",
    "    test_res  = test_df[\"actual\"]  - test_df[\"prediction\"]\n",
    "\n",
    "    # 2) helper to get sample vs theoretical quantiles\n",
    "    def qq_data(res):\n",
    "        res_sorted = np.sort(res)\n",
    "        n = len(res_sorted)\n",
    "        probs = (np.arange(1, n+1) - 0.5) / n\n",
    "        # theoretical N(μ,σ) quantiles\n",
    "        mu, sigma = res_sorted.mean(), res_sorted.std(ddof=0)\n",
    "        theor = stats.norm.ppf(probs) * sigma + mu\n",
    "        return theor, res_sorted\n",
    "    \n",
    "    theor_tr, res_tr = qq_data(train_res)\n",
    "    theor_te, res_te = qq_data(test_res)\n",
    "    \n",
    "    # 3) determine global plotting range for y=x reference\n",
    "    lo = min(theor_tr.min(), res_tr.min(), theor_te.min(), res_te.min())\n",
    "    hi = max(theor_tr.max(), res_tr.max(), theor_te.max(), res_te.max())\n",
    "    \n",
    "    # 4) build figure\n",
    "    fig = go.Figure()\n",
    "    # colors\n",
    "    palette = px.colors.qualitative.Plotly\n",
    "    train_color, test_color = palette[0], palette[1]\n",
    "    \n",
    "    # train Q–Q\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=theor_tr,\n",
    "        y=res_tr,\n",
    "        mode=\"markers\",\n",
    "        name=\"Train\",\n",
    "        line=dict(color=train_color, width=2),\n",
    "        marker=dict(opacity=0.8)\n",
    "    ))\n",
    "    \n",
    "    # test Q–Q\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=theor_te,\n",
    "        y=res_te,\n",
    "        mode=\"markers\",\n",
    "        name=\"Test\",\n",
    "        line=dict(color=test_color, width=2),\n",
    "        marker=dict(symbol=\"x\", opacity=0.8),\n",
    "    ))\n",
    "\n",
    "    # dashed y=x reference, hidden by default\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[lo, hi], y=[lo, hi],\n",
    "        mode=\"lines\",\n",
    "        name=\"Baseline (y=x)\",\n",
    "        line=dict(color=\"grey\", dash=\"dash\"),\n",
    "        visible=\"legendonly\"\n",
    "    ))\n",
    "\n",
    "    # 5) styling\n",
    "    fig.update_layout(\n",
    "        title=dict(text=\"Normal Q–Q Plot of Residuals (Train & Test)\", x=0.5),\n",
    "        legend=dict(orientation=\"h\", x=0.5, y=-0.15, xanchor=\"center\", yanchor=\"top\"),\n",
    "        xaxis_title=\"Theoretical Quantiles (Normal)\",\n",
    "        yaxis_title=\"Sample Quantiles (Residuals)\",\n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\",\n",
    "        width=700, height=500,\n",
    "        margin=dict(t=80, b=60)\n",
    "    )\n",
    "    fig.update_xaxes(showgrid=True, gridcolor=\"lightgrey\", zeroline=False, showline=False)\n",
    "    fig.update_yaxes(showgrid=True, gridcolor=\"lightgrey\", zeroline=False, showline=False)\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7eaa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_qq_plot(train_pandas_df, test_pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225eb3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "def residual_and_error_toggle(train_df, test_df, bins=50):\n",
    "    \"\"\"\n",
    "    Creates a single Plotly figure with a toggle between:\n",
    "      - signed residual distribution (y - ŷ)\n",
    "      - absolute error distribution |y - ŷ|\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_df, test_df : pandas.DataFrame\n",
    "        Must each have 'actual' and 'prediction' columns.\n",
    "    bins : int\n",
    "        Number of bins for the histograms.\n",
    "    \"\"\"\n",
    "    # compute residuals and errors\n",
    "    train_res = train_df[\"actual\"] - train_df[\"prediction\"]\n",
    "    test_res  = test_df[\"actual\"]  - test_df[\"prediction\"]\n",
    "    train_err = train_res.abs()\n",
    "    test_err  = test_res.abs()\n",
    "\n",
    "    # colors\n",
    "    palette = px.colors.qualitative.Plotly\n",
    "    train_color, test_color = palette[0], palette[1]\n",
    "\n",
    "    # build all four traces\n",
    "    fig = go.Figure([\n",
    "        # residuals\n",
    "        go.Histogram(x=train_res, nbinsx=bins, name=\"Train Residual\", marker=dict(color=train_color, line=dict(color='white', width=1)), opacity=0.8),\n",
    "        go.Histogram(x=test_res,  nbinsx=bins, name=\"Test Residual\",  marker=dict(color=test_color, line=dict(color='white', width=1)), opacity=0.8),\n",
    "        # absolute errors\n",
    "        go.Histogram(x=train_err, nbinsx=bins, name=\"Train Error\",    marker=dict(color=train_color, line=dict(color='white', width=1)), opacity=0.8,),\n",
    "        go.Histogram(x=test_err,  nbinsx=bins, name=\"Test Error\",     marker=dict(color=test_color, line=dict(color='white', width=1)), opacity=0.8,),\n",
    "    ])\n",
    "\n",
    "    # overlay mode\n",
    "    fig.update_layout(barmode='overlay', bargap=0.1)\n",
    "\n",
    "    # initially show residuals only\n",
    "    fig.data[0].visible = True\n",
    "    fig.data[1].visible = True\n",
    "    fig.data[2].visible = False\n",
    "    fig.data[3].visible = False\n",
    "\n",
    "    # updatemenu buttons\n",
    "    buttons = [\n",
    "        dict(label=\"Residuals\",\n",
    "             method=\"update\",\n",
    "             args=[{\"visible\": [True, True, False, False]},\n",
    "                   {\"title\": \"Residual Distribution\",\n",
    "                    \"yaxis\":{\"title\":\"Count\"}}]),\n",
    "        dict(label=\"Absolute Errors\",\n",
    "             method=\"update\",\n",
    "             args=[{\"visible\": [False, False, True, True]},\n",
    "                   {\"title\": \"Absolute Error Distribution\",\n",
    "                    \"yaxis\":{\"title\":\"Count\"}}]),\n",
    "    ]\n",
    "\n",
    "    fig.update_layout(\n",
    "        updatemenus=[dict(\n",
    "            type=\"buttons\",\n",
    "            buttons=buttons,\n",
    "            direction=\"left\",\n",
    "            pad={\"r\":10,\"t\":10},\n",
    "            showactive=True,\n",
    "            x=0.5,\n",
    "            xanchor=\"center\",\n",
    "            y=1.15,\n",
    "            yanchor=\"top\"\n",
    "        )],\n",
    "        title=dict(text=\"Residual Distribution\", x=0.5),\n",
    "        legend=dict(orientation=\"h\", x=0.5, y=-0.15, xanchor=\"center\", yanchor=\"top\"),\n",
    "        xaxis_title=\"Value\",\n",
    "        yaxis_title=\"Count\",\n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\",\n",
    "        width=700,\n",
    "        height=500,\n",
    "        margin=dict(t=100, b=60),\n",
    "        hovermode=\"x\"\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(showgrid=True, gridcolor=\"lightgrey\", zeroline=False, showline=False)\n",
    "    fig.update_yaxes(showgrid=True, gridcolor=\"lightgrey\", zeroline=False, showline=False)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_and_error_toggle(train_pandas_df, test_pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb3ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def rec_curve(train_df, test_df, num_points=200):\n",
    "    \"\"\"\n",
    "    Plots Regression Error Characteristic (REC) curves for train & test.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_df : pandas.DataFrame\n",
    "        Must contain 'actual' and 'prediction' columns.\n",
    "    test_df : pandas.DataFrame\n",
    "        Must contain 'actual' and 'prediction' columns.\n",
    "    num_points : int, default=200\n",
    "        Number of points in the tolerance grid.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fig : plotly.graph_objects.Figure\n",
    "    \"\"\"\n",
    "    # compute abs errors\n",
    "    train_err = np.abs(train_df[\"actual\"] - train_df[\"prediction\"])\n",
    "    test_err  = np.abs(test_df[\"actual\"]  - test_df[\"prediction\"])\n",
    "    \n",
    "    # tolerance grid from 0 to max error\n",
    "    max_err = max(train_err.max(), test_err.max())\n",
    "    tol = np.linspace(0, max_err, num_points)\n",
    "    \n",
    "    # compute CDF (% of samples within each tolerance)\n",
    "    train_cdf = [(train_err <= t).mean() * 100 for t in tol]\n",
    "    test_cdf  = [(test_err  <= t).mean() * 100 for t in tol]\n",
    "    \n",
    "    # build figure\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=tol, y=train_cdf, mode=\"lines\", name=\"Train\",\n",
    "        line=dict(width=2, dash=\"dot\")\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=tol, y=test_cdf, mode=\"lines\", name=\"Test\",\n",
    "        line=dict(width=2, dash=\"dot\")\n",
    "    ))\n",
    "    \n",
    "    # styling\n",
    "    fig.update_layout(\n",
    "        title=dict(text=\"Regression Error Characteristic (REC) Curve\", x=0.5),\n",
    "        xaxis_title=\"Error Tolerance (|y – ŷ|)\",\n",
    "        yaxis_title=\"% Samples within Tolerance\",\n",
    "        legend=dict(orientation=\"h\", x=0.5, y=-0.15, xanchor=\"center\", yanchor=\"top\"),\n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\",\n",
    "        width=700, height=500,\n",
    "        margin=dict(t=80, b=60),\n",
    "        hovermode=\"x unified\"\n",
    "    )\n",
    "    fig.update_xaxes(showgrid=True, gridcolor=\"lightgrey\", zeroline=False, showline=False)\n",
    "    fig.update_yaxes(showgrid=True, gridcolor=\"lightgrey\", zeroline=False, showline=False, range=[0,100])\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dadc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_curve(train_pandas_df, test_pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d44d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "def calibration_plot(train_df, test_df, bins=10):\n",
    "    \"\"\"\n",
    "    Plots a Binned Residual Mean (Calibration) plot:\n",
    "    - Bins data by predicted values into quantiles\n",
    "    - Computes average predicted vs average actual in each bin\n",
    "    - Overlays train & test curves plus the y=x identity line\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_df : pandas.DataFrame\n",
    "        Must contain 'actual' and 'prediction' columns.\n",
    "    test_df : pandas.DataFrame\n",
    "        Must contain 'actual' and 'prediction' columns.\n",
    "    bins : int\n",
    "        Number of quantile-based bins.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig : plotly.graph_objects.Figure\n",
    "    \"\"\"\n",
    "    # 1) make copies & bin by predicted quantiles\n",
    "    t = train_df.copy()\n",
    "    v = test_df.copy()\n",
    "    t['bin'] = pd.qcut(t['prediction'], q=bins, duplicates='drop')\n",
    "    v['bin'] = pd.qcut(v['prediction'], q=bins, duplicates='drop')\n",
    "\n",
    "    # 2) aggregate means per bin\n",
    "    train_grp = (\n",
    "        t.groupby('bin')\n",
    "         .agg(avg_pred=('prediction','mean'),\n",
    "              avg_actual=('actual','mean'))\n",
    "         .reset_index()\n",
    "    )\n",
    "    test_grp = (\n",
    "        v.groupby('bin')\n",
    "         .agg(avg_pred=('prediction','mean'),\n",
    "              avg_actual=('actual','mean'))\n",
    "         .reset_index()\n",
    "    )\n",
    "\n",
    "    # 3) global min/max for identity line\n",
    "    all_vals = pd.concat([\n",
    "        train_grp['avg_pred'], train_grp['avg_actual'],\n",
    "        test_grp['avg_pred'],  test_grp['avg_actual']\n",
    "    ])\n",
    "    lo, hi = all_vals.min(), all_vals.max()\n",
    "\n",
    "    # 4) colors\n",
    "    palette = px.colors.qualitative.Plotly\n",
    "    train_color, test_color = palette[0], palette[1]\n",
    "\n",
    "    # 5) build figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # identity line y = x\n",
    "    fig.add_shape(\n",
    "        type='line',\n",
    "        xref='x', yref='y',\n",
    "        x0=lo, y0=lo,\n",
    "        x1=hi, y1=hi,\n",
    "        line=dict(color='black', dash='dash')\n",
    "    )\n",
    "\n",
    "    # train curve\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=train_grp['avg_pred'],\n",
    "        x=train_grp['avg_actual'],\n",
    "        mode='lines+markers',\n",
    "        name='Train',\n",
    "        line=dict(color=train_color),\n",
    "        marker=dict(color=train_color)\n",
    "    ))\n",
    "\n",
    "    # test curve\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=test_grp['avg_pred'],\n",
    "        x=test_grp['avg_actual'],\n",
    "        mode='lines+markers',\n",
    "        name='Test',\n",
    "        line=dict(color=test_color, dash='dot'),\n",
    "        marker=dict(color=test_color, symbol='x')\n",
    "    ))\n",
    "\n",
    "    # 6) styling\n",
    "    fig.update_layout(\n",
    "        title=dict(text='Calibration Plot (Binned Actual vs Predicted)', x=0.5),\n",
    "        legend=dict(orientation='h',\n",
    "                    x=0.5, xanchor='center',\n",
    "                    y=-0.15, yanchor='top'),\n",
    "        yaxis_title='Average Predicted',\n",
    "        xaxis_title='Average Actual',\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white',\n",
    "        width=700,\n",
    "        height=500,\n",
    "        margin=dict(t=80, b=60)\n",
    "    )\n",
    "    fig.update_xaxes(showgrid=True, gridcolor='lightgrey',\n",
    "                     zeroline=False, showline=False)\n",
    "    fig.update_yaxes(showgrid=True, gridcolor='lightgrey',\n",
    "                     zeroline=False, showline=False)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e544791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_plot(train_pandas_df, test_pandas_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
