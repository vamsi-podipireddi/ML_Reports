{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a964bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23192870",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PandasToSpark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7226441",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "sample_0 = train_df[train_df[\"actual\"] == 0].sample(n=50, random_state=42)\n",
    "sample_1 = train_df[train_df[\"actual\"] == 1].sample(n=50, random_state=42)\n",
    "sampled_train_df = pd.concat([sample_0, sample_1]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "sampled_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b7b05",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "sample_0 = test_df[test_df[\"actual\"] == 0].sample(n=50, random_state=42)\n",
    "sample_1 = test_df[test_df[\"actual\"] == 1].sample(n=30, random_state=42)\n",
    "sampled_test_df = pd.concat([sample_0, sample_1]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "sampled_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spark_df = spark.createDataFrame(sampled_train_df)\n",
    "test_spark_df = spark.createDataFrame(sampled_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c503e3",
   "metadata": {},
   "source": [
    "## Plot 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf6c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from pyspark.sql.functions import col\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.colors import sample_colorscale\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# Configuration for bar color mapping: invert True for metrics where lower is better\n",
    "METRICS_CONFIG = {\n",
    "    \"accuracy\":           {\"invert\": False},\n",
    "    \"precision\":          {\"invert\": False},\n",
    "    \"recall\":             {\"invert\": False},\n",
    "    \"f1\":                 {\"invert\": False},\n",
    "    \"specificity\":        {\"invert\": False},\n",
    "    \"npv\":                {\"invert\": False},\n",
    "    \"balanced_accuracy\":  {\"invert\": False},\n",
    "    \"jaccard\":            {\"invert\": False},\n",
    "    \"gmean\":              {\"invert\": False},\n",
    "    \"hamming_loss\":       {\"invert\": True}  # lower is better\n",
    "}\n",
    "\n",
    "CM_X = [\"Predicted '0'\", \"Predicted '1'\"]\n",
    "CM_Y = [\"Actual '0'\", \"Actual '1'\"]\n",
    "\n",
    "def _compute_threshold_metrics(df_spark, label_col: str, probability_col: str,\n",
    "                               thresholds: List[float], extra_metrics: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute confusion matrix counts and classification metrics across given thresholds.\n",
    "\n",
    "    Parameters:\n",
    "        df_spark: Input Spark DataFrame.\n",
    "        label_col (str): Column name for the true label.\n",
    "        probability_col (str): Column name for prediction probability.\n",
    "        thresholds (List[float]): List of threshold values to compute metrics.\n",
    "        extra_metrics (bool): Whether to compute additional metrics.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing confusion matrix counts and metrics for each threshold.\n",
    "    \"\"\"\n",
    "    # Cast probability and label columns to double for calculation consistency.\n",
    "    df = df_spark.withColumn(\"score\", col(probability_col).cast(\"double\"))\n",
    "    df = df.withColumn(\"label_d\", col(label_col).cast(\"double\"))\n",
    "\n",
    "    rows = []\n",
    "    for t in thresholds:\n",
    "        # Compute prediction based on threshold\n",
    "        pred = df.withColumn(\"pred_t\", (col(\"score\") >= t).cast(\"double\"))\n",
    "        # Create confusion matrix using pivot operation and fill missing counts with zero\n",
    "        cm = (pred.groupBy(\"label_d\")\n",
    "                  .pivot(\"pred_t\", [0.0, 1.0])\n",
    "                  .count().na.fill(0).orderBy(\"label_d\").collect())\n",
    "        # Extract TN, FP, FN, TP counts from confusion matrix\n",
    "        TN, FP = cm[0][1], cm[0][2]\n",
    "        FN, TP = cm[1][1], cm[1][2]\n",
    "        total = TP + TN + FP + FN\n",
    "\n",
    "        # Calculate primary metrics: accuracy, precision, recall, and f1 score.\n",
    "        acc  = (TP + TN) / total if total else 0.0\n",
    "        prec = TP / (TP + FP)    if (TP + FP) else 0.0\n",
    "        rec  = TP / (TP + FN)    if (TP + FN) else 0.0\n",
    "        f1   = (2 * prec * rec) / (prec + rec) if (prec + rec) else 0.0\n",
    "\n",
    "        row = {\"threshold\": t, \"TN\": TN, \"FP\": FP, \"FN\": FN, \"TP\": TP,\n",
    "               \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1}\n",
    "\n",
    "        # If extra_metrics is True, calculate additional metrics.\n",
    "        if extra_metrics:\n",
    "            spec = TN / (TN + FP) if (TN + FP) else 0.0\n",
    "            npv  = TN / (TN + FN) if (TN + FN) else 0.0\n",
    "            bal_acc = (rec + spec) / 2\n",
    "            jaccard = TP / (TP + FP + FN) if (TP + FP + FN) else 0.0\n",
    "            gmean   = math.sqrt(rec * spec) if rec * spec >= 0 else 0.0\n",
    "            h_loss  = (FP + FN) / total if total else 0.0\n",
    "            row.update({\"specificity\": spec, \"npv\": npv,\n",
    "                        \"balanced_accuracy\": bal_acc,\n",
    "                        \"jaccard\": jaccard, \"gmean\": gmean,\n",
    "                        \"hamming_loss\": h_loss})\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def _metric_color(value: float, invert: bool) -> str:\n",
    "    \"\"\"\n",
    "    Map metric value to a color on the RdYlGn scale.\n",
    "\n",
    "    Parameters:\n",
    "        value (float): The metric value.\n",
    "        invert (bool): Whether to invert the value (for metrics where lower is better).\n",
    "\n",
    "    Returns:\n",
    "        str: The color corresponding to the metric value.\n",
    "    \"\"\"\n",
    "    # Invert the value if required for color scaling\n",
    "    scaled = 1 - value if invert else value\n",
    "    return sample_colorscale('RdYlGn', [scaled])[0]\n",
    "\n",
    "def _create_slider_steps(df_metrics: pd.DataFrame, metrics: List[str]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Generate Plotly slider steps for each threshold, updating confusion matrix and metrics.\n",
    "\n",
    "    Parameters:\n",
    "        df_metrics (pd.DataFrame): DataFrame containing metrics for each threshold.\n",
    "        metrics (List[str]): List of metric names to be displayed in the bar chart.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: List of slider step configurations.\n",
    "    \"\"\"\n",
    "    steps = []\n",
    "    for _, r in df_metrics.iterrows():\n",
    "        # Build confusion matrix from metric row\n",
    "        z = [[r.TN, r.FP], [r.FN, r.TP]]\n",
    "        # Collect metric values for the bar chart\n",
    "        vals = [r[m] for m in metrics]\n",
    "        # Determine color for each metric bar based on its value and configuration\n",
    "        bar_colors = [_metric_color(r[m], METRICS_CONFIG[m][\"invert\"]) for m in metrics]\n",
    "        bar_text = [f\"{v:.2f}\" for v in vals]\n",
    "\n",
    "        steps.append({\n",
    "            'method': 'update',\n",
    "            'args': [\n",
    "                {\n",
    "                    'z': [z, None],\n",
    "                    'x': [CM_X, vals],\n",
    "                    'marker.color': [None, bar_colors],\n",
    "                    'text': [z, bar_text]\n",
    "                },\n",
    "                {'transition': {'duration': 500, 'easing': 'linear'}}\n",
    "            ],\n",
    "            'label': f\"{r.threshold:.2f}\"\n",
    "        })\n",
    "    return steps\n",
    "\n",
    "def _configure_slider(steps: List[Dict], active_index: int) -> Dict:\n",
    "    return {\n",
    "        \"active\": active_index,\n",
    "        \"pad\": {\"t\": 50},\n",
    "        \"len\": 0.8,\n",
    "        \"x\": 0.1,\n",
    "        \"steps\": steps,\n",
    "        \"currentvalue\": {\n",
    "            \"visible\": True,\n",
    "            \"prefix\": \"Threshold: \",\n",
    "            \"xanchor\": \"center\",\n",
    "            \"font\": {\"size\": 14, \"color\": \"black\"},\n",
    "        },\n",
    "        # hide every tick-mark\n",
    "        \"ticklen\":   0,\n",
    "        \"tickwidth\": 0,\n",
    "        \"tickcolor\": \"rgba(0,0,0,0)\",\n",
    "        \"font\": {\"color\": \"rgba(0,0,0,0)\"},  # still hide the labels\n",
    "        \"bgcolor\": \"white\",\n",
    "        \"bordercolor\": \"lightgray\",\n",
    "    }\n",
    "\n",
    "\n",
    "def _initialize_figure(initial_z: List[List[int]], initial_vals: List[float], metrics: List[str]) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Initialize a Plotly figure with a confusion matrix heatmap and a metrics bar chart.\n",
    "\n",
    "    Parameters:\n",
    "        initial_z (List[List[int]]): Initial confusion matrix counts.\n",
    "        initial_vals (List[float]): Initial metric values for the bar chart.\n",
    "        metrics (List[str]): Metrics to be displayed.\n",
    "\n",
    "    Returns:\n",
    "        go.Figure: Initialized Plotly figure.\n",
    "    \"\"\"\n",
    "    # Create subplots with two columns: one for confusion matrix and one for metrics\n",
    "    fig = make_subplots(rows=1, cols=2, column_widths=[0.5, 0.5],\n",
    "                        subplot_titles=(\"Confusion Matrix\", \"Metrics\"))\n",
    "\n",
    "    # Add confusion matrix heatmap on the left subplot\n",
    "    fig.add_trace(go.Heatmap(\n",
    "        z=initial_z, x=CM_X, y=CM_Y,\n",
    "        text=initial_z, texttemplate=\"%{text}\", showscale=False,\n",
    "        colorscale=\"Greens\"\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    # Calculate bar colors for the metrics\n",
    "    bar_colors = [_metric_color(val, METRICS_CONFIG[m][\"invert\"]) for val, m in zip(initial_vals, metrics)]\n",
    "    # Add horizontal bar chart on the right subplot\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=metrics, x=initial_vals, orientation='h',\n",
    "        marker_color=bar_colors,\n",
    "        text=[f\"{v:.2f}\" for v in initial_vals], textposition='auto'\n",
    "    ), row=1, col=2)\n",
    "\n",
    "    return fig\n",
    "\n",
    "def _style_figure(fig: go.Figure, slider: Dict) -> None:\n",
    "    \"\"\"\n",
    "    Apply layout styles, axis formatting, and font styling to the Plotly figure.\n",
    "\n",
    "    Parameters:\n",
    "        fig (go.Figure): The Plotly figure to be styled.\n",
    "        slider (Dict): The slider configuration to be applied.\n",
    "    \"\"\"\n",
    "    # Update global layout attributes\n",
    "    fig.update_layout(\n",
    "        sliders=[slider],\n",
    "        transition={'duration': 500, 'easing': 'linear'},\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white',\n",
    "        font={'family': 'sans-serif', 'size': 12, 'color': '#333'}\n",
    "    )\n",
    "    # Configure x and y axes for both subplots\n",
    "    fig.update_xaxes(showgrid=False, ticklabelstandoff=10, tickfont=dict(size=12, family='sans-serif'))\n",
    "    fig.update_yaxes(showgrid=False, ticklabelstandoff=10, tickfont=dict(size=12, family='sans-serif'))\n",
    "    fig.update_xaxes(tickmode='array', tickvals=CM_X, type='category', row=1, col=1)\n",
    "    fig.update_yaxes(tickmode='array', tickvals=CM_Y, type='category', row=1, col=1)\n",
    "    fig.update_xaxes(autorange=False, showticklabels=False, range=[1, 0], row=1, col=2)\n",
    "    fig.update_yaxes(side='right', row=1, col=2)\n",
    "\n",
    "    # Enhance subplot titles appearance\n",
    "    for ann in fig.layout.annotations:\n",
    "        ann.text = f\"<b>{ann.text}</b>\"\n",
    "        ann.y += 0.05\n",
    "        ann.font = {'family': 'sans-serif', 'size': 16, 'color': 'DarkSlateGray'}\n",
    "\n",
    "def plot_metrics_confusion_interactive(\n",
    "    spark_df,\n",
    "    label_col: str = 'label',\n",
    "    probability_col: str = 'probability',\n",
    "    thresholds: Optional[List[float]] = None,\n",
    "    default_threshold: float = 0.50,\n",
    "    extra_metrics: bool = False\n",
    ") -> go.Figure:\n",
    "    \"\"\"\n",
    "    Build an interactive Plotly figure that displays a confusion matrix and\n",
    "    classification metrics with a slider to animate over different thresholds.\n",
    "\n",
    "    Parameters:\n",
    "        spark_df: Input Spark DataFrame.\n",
    "        label_col (str): Name of the column containing true labels.\n",
    "        probability_col (str): Name of the column containing probability scores.\n",
    "        thresholds (Optional[List[float]]): List of threshold values. Defaults to a range from 0.0 to 1.0.\n",
    "        default_threshold (float): The default active threshold value.\n",
    "        extra_metrics (bool): Whether to compute and display extra metrics.\n",
    "\n",
    "    Returns:\n",
    "        go.Figure: The interactive Plotly figure.\n",
    "    \"\"\"\n",
    "    # Define default thresholds if not provided\n",
    "    if thresholds is None:\n",
    "        thresholds = np.arange(0.0, 1.01, 0.05).tolist()\n",
    "    # Find the index of the default threshold if present\n",
    "    default_idx = thresholds.index(default_threshold) if default_threshold in thresholds else 0\n",
    "\n",
    "    # Compute metrics for each threshold using the private helper function\n",
    "    dfm = _compute_threshold_metrics(spark_df, label_col, probability_col, thresholds, extra_metrics)\n",
    "\n",
    "    # Define main and extra metrics based on the extra_metrics flag\n",
    "    base = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    extra = ['specificity', 'npv', 'balanced_accuracy', 'jaccard', 'gmean', 'hamming_loss'] if extra_metrics else []\n",
    "    metrics = base + extra\n",
    "\n",
    "    # Get initial data from the default threshold row\n",
    "    init = dfm.iloc[default_idx]\n",
    "    initial_z = [[init.TN, init.FP], [init.FN, init.TP]]\n",
    "    initial_vals = [init[m] for m in metrics]\n",
    "\n",
    "    # Initialize the figure, create the slider steps, and apply styling\n",
    "    fig = _initialize_figure(initial_z, initial_vals, metrics)\n",
    "    steps = _create_slider_steps(dfm, metrics)\n",
    "    slider = _configure_slider(steps, default_idx)\n",
    "    _style_figure(fig, slider)\n",
    "\n",
    "    return fig, dfm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2224482",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fig, train_eval_df = plot_metrics_confusion_interactive(\n",
    "    train_spark_df,\n",
    "    label_col=\"actual\",\n",
    "    extra_metrics=True,\n",
    "    thresholds=np.arange(0.0, 1.01, 0.01).tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7287aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fig, test_eval_df = plot_metrics_confusion_interactive(\n",
    "    test_spark_df,\n",
    "    label_col=\"actual\",\n",
    "    extra_metrics=True,\n",
    "    thresholds=np.arange(0.0, 1.01, 0.01).tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3404d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7071ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2762b38",
   "metadata": {},
   "source": [
    "## Plot 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1888d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from typing import List\n",
    "\n",
    "def plot_interactive_scatter(df: pd.DataFrame, label_col: str = \"label\"):\n",
    "    \"\"\"\n",
    "    Create an interactive scatter plot with dropdowns to select X and Y axes,\n",
    "    coloring the points by the specified label column.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Input Pandas DataFrame\n",
    "    - label_col: Name of the label column for color grouping\n",
    "    \"\"\"\n",
    "    # Identify numeric columns excluding the label\n",
    "    numeric_cols: List[str] = df.select_dtypes(include='number').columns.drop(label_col).tolist()\n",
    "\n",
    "    # Create base figure (first pair of columns)\n",
    "    fig = px.scatter(df, x=numeric_cols[0], y=numeric_cols[1], color=label_col,\n",
    "                     title=\"Interactive Scatter Plot by Label\",\n",
    "                     labels={label_col: label_col})\n",
    "\n",
    "    # Dropdown for x-axis\n",
    "    x_dropdown = [\n",
    "        dict(label=col, method=\"update\",\n",
    "             args=[{\"x\": [df[col]]},\n",
    "                   {\"xaxis\": {\"title\": col}}])\n",
    "        for col in numeric_cols\n",
    "    ]\n",
    "\n",
    "    # Dropdown for y-axis\n",
    "    y_dropdown = [\n",
    "        dict(label=col, method=\"update\",\n",
    "             args=[{\"y\": [df[col]]},\n",
    "                   {\"yaxis\": {\"title\": col}}])\n",
    "        for col in numeric_cols\n",
    "    ]\n",
    "\n",
    "    # Update layout with dropdown menus\n",
    "    fig.update_layout(\n",
    "        updatemenus=[\n",
    "            dict(buttons=x_dropdown, direction=\"down\", showactive=True,\n",
    "                 x=0.0, y=1.15, xanchor=\"left\", yanchor=\"top\",\n",
    "                 pad={\"r\": 10, \"t\": 10},\n",
    "                 name=\"X Axis\"),\n",
    "            dict(buttons=y_dropdown, direction=\"down\", showactive=True,\n",
    "                 x=0.25, y=1.15, xanchor=\"left\", yanchor=\"top\",\n",
    "                 pad={\"r\": 10, \"t\": 10},\n",
    "                 name=\"Y Axis\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Style and return\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\",\n",
    "        font=dict(family=\"sans-serif\", size=12, color=\"#333\")\n",
    "    )\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fdf5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interactive_scatter(\n",
    "    train_df,\n",
    "    label_col=\"actual\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118b15e7",
   "metadata": {},
   "source": [
    "## Plot 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0391e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_feature_distribution_with_prediction(\n",
    "    df: pd.DataFrame,\n",
    "    feature: str,\n",
    "    label_col: str = \"label\",\n",
    "    probability_col: str = \"probability\",\n",
    "    threshold_values: np.ndarray = np.arange(0.0, 1.01, 0.05)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots side-by-side KDE plots of a numerical feature for:\n",
    "    - Actual labels (static)\n",
    "    - Predicted labels (interactive with threshold slider)\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with actual and predicted probability columns\n",
    "    - feature: feature column to plot\n",
    "    - label_col: name of actual label column\n",
    "    - probability_col: name of predicted probability column\n",
    "    - threshold_values: list of thresholds to animate predictions\n",
    "    \"\"\"\n",
    "    if feature not in df.columns or label_col not in df.columns or probability_col not in df.columns:\n",
    "        raise ValueError(\"One or more columns not found in the DataFrame\")\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=(\"Actual Labels\", \"Predicted Labels\"),\n",
    "        column_widths=[0.5, 0.5]\n",
    "    )\n",
    "\n",
    "    # --- Static: Actual KDEs ---\n",
    "    actual_labels = sorted(df[label_col].dropna().unique())\n",
    "    for label in actual_labels:\n",
    "        data = df[df[label_col] == label][feature].dropna()\n",
    "        if len(data) > 1:\n",
    "            kde = gaussian_kde(data)\n",
    "            x_vals = np.linspace(data.min(), data.max(), 100)\n",
    "            y_vals = kde(x_vals)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x_vals,\n",
    "                    y=y_vals,\n",
    "                    mode='lines',\n",
    "                    name=f\"Actual {label}\",\n",
    "                    fill='tozeroy',\n",
    "                    legendgroup=f\"actual_{label}\"\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "\n",
    "    # --- Static: First threshold predictions ---\n",
    "    t0 = threshold_values[0]\n",
    "    df[\"pred_label\"] = (df[probability_col] >= t0).astype(int)\n",
    "    pred_labels = sorted(df[\"pred_label\"].unique())\n",
    "\n",
    "    for label in pred_labels:\n",
    "        data = df[df[\"pred_label\"] == label][feature].dropna()\n",
    "        if len(data) > 1:\n",
    "            kde = gaussian_kde(data)\n",
    "            x_vals = np.linspace(data.min(), data.max(), 100)\n",
    "            y_vals = kde(x_vals)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x_vals,\n",
    "                    y=y_vals,\n",
    "                    mode='lines',\n",
    "                    name=f\"Pred {label}\",\n",
    "                    fill='tozeroy',\n",
    "                    legendgroup=f\"pred_{label}\"\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "\n",
    "    # --- Build frames for predicted side ---\n",
    "    frames = []\n",
    "    for t in threshold_values:\n",
    "        df[\"pred_label\"] = (df[probability_col] >= t).astype(int)\n",
    "        traces = []\n",
    "        for label in sorted(df[\"pred_label\"].unique()):\n",
    "            data = df[df[\"pred_label\"] == label][feature].dropna()\n",
    "            if len(data) > 1:\n",
    "                kde = gaussian_kde(data)\n",
    "                x_vals = np.linspace(data.min(), data.max(), 100)\n",
    "                y_vals = kde(x_vals)\n",
    "                traces.append(go.Scatter(\n",
    "                    x=x_vals,\n",
    "                    y=y_vals,\n",
    "                    mode='lines',\n",
    "                    name=f\"Pred {label}\",\n",
    "                    fill='tozeroy',\n",
    "                    legendgroup=f\"pred_{label}\",\n",
    "                    showlegend=False\n",
    "                ))\n",
    "        frames.append(go.Frame(data=traces, name=f\"{t:.2f}\"))\n",
    "\n",
    "    fig.frames = frames\n",
    "\n",
    "    # --- Slider ---\n",
    "    steps = [{\n",
    "        \"method\": \"animate\",\n",
    "        \"args\": [[f\"{t:.2f}\"], {\"mode\": \"immediate\", \"frame\": {\"duration\": 500, \"redraw\": True}}],\n",
    "        \"label\": f\"{t:.2f}\"\n",
    "    } for t in threshold_values]\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Feature Distribution: {feature}\",\n",
    "        sliders=[{\n",
    "            \"steps\": steps,\n",
    "            \"active\": 0,\n",
    "            \"x\": 0.1,\n",
    "            \"len\": 0.8,\n",
    "            \"pad\": {\"t\": 50},\n",
    "            \"currentvalue\": {\n",
    "                \"visible\": True,\n",
    "                \"prefix\": \"Threshold: \",\n",
    "                \"xanchor\": \"center\",\n",
    "                \"font\": {\"size\": 14}\n",
    "            },\n",
    "        }],\n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\",\n",
    "        font={\"family\": \"sans-serif\", \"size\": 12, \"color\": \"#333\"}\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ff684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols: List[str] = df.columns.drop(label_col).tolist()\n",
    "total_rows = len(df)\n",
    "\n",
    "# Determine feature types based on the provided definition\n",
    "feature_types = {}\n",
    "for col in feature_cols:\n",
    "    unique_ratio = (df[col].nunique() / total_rows) * 100\n",
    "    feature_types[col] = 'numerical' if unique_ratio > 1 else 'categorical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a6df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_df.columns:\n",
    "    print(f\"{col}: {train_df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b451c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distribution_with_prediction(train_df,\"EstimatedSalary\", \"actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distribution(train_df,\"Age\", \"actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distribution(train_df,\"Tenure\", \"actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb537cb",
   "metadata": {},
   "source": [
    "## Plot 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ─── Helpers ────────────────────────────────────────────────────────────────\n",
    "\n",
    "def compute_auc(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"Simple trapezoidal AUC.\"\"\"\n",
    "    return np.trapz(y, x)\n",
    "\n",
    "def make_zone_polygons(random_fpr: np.ndarray, random_tpr: np.ndarray):\n",
    "    \"\"\"Return two dicts of kwargs for the red (below) and green (above) fill polygons.\"\"\"\n",
    "    red = dict(\n",
    "        x=np.concatenate([random_fpr, random_fpr[::-1]]),\n",
    "        y=np.concatenate([random_tpr, np.zeros_like(random_tpr)]),\n",
    "        fill='toself', fillcolor='rgba(255,0,0,0.2)', line=dict(width=0),\n",
    "        hoverinfo='skip', showlegend=False\n",
    "    )\n",
    "    green = dict(\n",
    "        x=np.concatenate([random_fpr, random_fpr[::-1]]),\n",
    "        y=np.concatenate([random_tpr, np.ones_like(random_tpr)]),\n",
    "        fill='toself', fillcolor='rgba(0,128,0,0.2)', line=dict(width=0),\n",
    "        hoverinfo='skip', showlegend=False\n",
    "    )\n",
    "    return red, green\n",
    "\n",
    "# ─── Main plotting function ─────────────────────────────────────────────────\n",
    "\n",
    "def plot_reference_rocs():\n",
    "    # 1) Define random diagonal\n",
    "    random_fpr = np.linspace(0, 1, 200)\n",
    "    random_tpr = random_fpr\n",
    "\n",
    "    # 2) Define curves and compute their AUCs\n",
    "    curves = [\n",
    "        {\n",
    "            \"name\": \"Random\",\n",
    "            \"x\": random_fpr, \"y\": random_tpr,\n",
    "            \"line\": dict(dash='dash', color='black', width=2),\n",
    "            \"annot_x\": 0.4, \"annot_y\": 0.4,\n",
    "            \"annot_offset\": (0.4, 0.55),\n",
    "            \"annot_color\": \"black\",\n",
    "            \"annot_text\": \"AUC=0.50 (Random)\",\n",
    "            \"textangle\": 0\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Perfect\",\n",
    "            \"x\": np.array([0, 0, 1]), \"y\": np.array([0, 1, 1]),\n",
    "            \"line\": dict(color='green', width=3),\n",
    "            \"annot_x\": 0.2, \"annot_y\": 1.0,\n",
    "            \"annot_offset\": (0.2, 1.1),\n",
    "            \"annot_color\": \"green\",\n",
    "            \"annot_text\": \"AUC=1.00 (Perfect)\",\n",
    "            \"textangle\": 0\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Good\",\n",
    "            \"x\": np.linspace(0, 1, 200),\n",
    "            \"y\": None,  # to be filled below\n",
    "            \"line\": dict(color='blue', width=3),\n",
    "            \"annot_x\": 0.3, \"annot_y\": None,\n",
    "            \"annot_offset\": (0.3, 0.8),\n",
    "            \"annot_color\": \"blue\",\n",
    "            \"annot_text\": \"AUC ∈ (0.5, 1) (Good)\",\n",
    "            \"textangle\": 0\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Poor\",\n",
    "            \"x\": np.linspace(0, 1, 200),\n",
    "            \"y\": None,\n",
    "            \"line\": dict(color='red', width=3),\n",
    "            \"annot_x\": 0.5, \"annot_y\": None,\n",
    "            \"annot_offset\": (0.5, 0.3),\n",
    "            \"annot_color\": \"red\",\n",
    "            \"annot_text\": \" AUC ∈ (0, 0.5) (Poor)\",\n",
    "            \"textangle\": 0\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Populate Good & Poor curves with data + AUC + annotation props\n",
    "    for c in curves:\n",
    "        if c[\"name\"] == \"Good\":\n",
    "            c[\"y\"] = np.cbrt(c[\"x\"])\n",
    "            auc = compute_auc(c[\"x\"], c[\"y\"])\n",
    "            c[\"annot_y\"] = np.cbrt(c[\"annot_x\"])\n",
    "        elif c[\"name\"] == \"Poor\":\n",
    "            c[\"y\"] = c[\"x\"]**3\n",
    "            auc = compute_auc(c[\"x\"], c[\"y\"])\n",
    "            c[\"annot_y\"] = c[\"annot_x\"]**3\n",
    "\n",
    "    # 3) Build figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # 3a) Add zones\n",
    "    red_zone, green_zone = make_zone_polygons(random_fpr, random_tpr)\n",
    "    fig.add_trace(go.Scatter(**red_zone))\n",
    "    fig.add_trace(go.Scatter(**green_zone))\n",
    "\n",
    "    # 3b) Add all curves\n",
    "    for c in curves:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=c[\"x\"], y=c[\"y\"], mode='lines',\n",
    "            line=c[\"line\"],\n",
    "            showlegend=False\n",
    "        ))\n",
    "\n",
    "    # 4) Add annotations\n",
    "    for c in curves:\n",
    "        fig.add_annotation(\n",
    "            x=c[\"annot_x\"], y=c[\"annot_y\"],\n",
    "            ax=c[\"annot_offset\"][0], ay=c[\"annot_offset\"][1],\n",
    "            xref=\"x\", yref=\"y\", axref=\"x\", ayref=\"y\",\n",
    "            text=c[\"annot_text\"],\n",
    "            showarrow=True, arrowhead=2, arrowsize=1,\n",
    "            arrowcolor=c[\"annot_color\"], arrowwidth=1,\n",
    "            textangle=c[\"textangle\"],\n",
    "            font=dict(color=c[\"annot_color\"], size=14)\n",
    "        )\n",
    "\n",
    "    # 5) Final layout\n",
    "    fig.update_layout(\n",
    "        title=\"Reference ROC Curves with On‐Curve AUC Labels\",\n",
    "        xaxis_title=\"False Positive Rate (1 – Specificity)\",\n",
    "        yaxis_title=\"True Positive Rate (Recall)\",\n",
    "        plot_bgcolor=\"white\", paper_bgcolor=\"white\",\n",
    "        width=700, height=600\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4142e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reference_rocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f39a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "def plot_roc_curve_area(train_eval_df: pd.DataFrame,\n",
    "                        test_eval_df: pd.DataFrame) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Overlay smooth ROC areas for train and test, hide their legend entries,\n",
    "    and place the AUC values inside the plot:\n",
    "      - if AUC > 0.5 → bottom-right,\n",
    "      - if AUC < 0.5 → top-left.\n",
    "    \"\"\"\n",
    "    def prepare(df):\n",
    "        dfc = df.copy()\n",
    "        dfc[\"fpr\"] = dfc[\"FP\"] / (dfc[\"FP\"] + dfc[\"TN\"])\n",
    "        dfc[\"tpr\"] = dfc[\"TP\"] / (dfc[\"TP\"] + dfc[\"FN\"])\n",
    "        dfc = dfc.sort_values(\"fpr\")\n",
    "        auc = np.trapz(dfc[\"tpr\"].values, dfc[\"fpr\"].values)\n",
    "        return dfc, auc\n",
    "\n",
    "    def pos_for_auc(auc: float):\n",
    "        # bottom-right if >0.5, else top-left\n",
    "        if auc > 0.5:\n",
    "            return dict(x=0.95, y=0.05, xanchor=\"right\", yanchor=\"bottom\")\n",
    "        else:\n",
    "            return dict(x=0.05, y=0.95, xanchor=\"left\",  yanchor=\"top\")\n",
    "\n",
    "    # prepare both\n",
    "    df_train, auc_train = prepare(train_eval_df)\n",
    "    df_test,  auc_test  = prepare(test_eval_df)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # ---- Train ROC trace ----\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_train[\"fpr\"], y=df_train[\"tpr\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Train ROC\",\n",
    "        hovertemplate=(\n",
    "            \"Train ROC<br>\"\n",
    "            \"Threshold %{text}<br>\"\n",
    "            \"FPR = %{x:.2f}<br>\"\n",
    "            \"TPR = %{y:.2f}<extra></extra>\"\n",
    "        ),\n",
    "        text=[f\"{t:.2f}\" for t in df_train[\"threshold\"]],\n",
    "        line=dict(color=\"rgb(31,119,180)\", shape=\"spline\", smoothing=1.3),\n",
    "        fill=\"tozeroy\", fillcolor=\"rgba(31,119,180,0.2)\",\n",
    "        marker=dict(size=6),\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    # ---- Test ROC trace ----\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_test[\"fpr\"], y=df_test[\"tpr\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Test ROC\",\n",
    "        hovertemplate=(\n",
    "            \"Test ROC<br>\"\n",
    "            \"Threshold %{text}<br>\"\n",
    "            \"FPR = %{x:.2f}<br>\"\n",
    "            \"TPR = %{y:.2f}<extra></extra>\"\n",
    "        ),\n",
    "        text=[f\"{t:.2f}\" for t in df_test[\"threshold\"]],\n",
    "        line=dict(color=\"rgb(255,127,14)\", shape=\"spline\", smoothing=1.3),\n",
    "        fill=\"tozeroy\", fillcolor=\"rgba(255,127,14,0.2)\",\n",
    "        marker=dict(size=6),\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    # Diagonal chance\n",
    "    fig.add_shape(\n",
    "        type=\"line\", x0=0, y0=0, x1=1, y1=1,\n",
    "        line=dict(dash=\"dash\", color=\"gray\")\n",
    "    )\n",
    "\n",
    "    # Place train AUC\n",
    "    p_train = pos_for_auc(auc_train)\n",
    "    fig.add_annotation(\n",
    "        text=f\"<b>Train AUC:</b> {auc_train:.2f}\",\n",
    "        showarrow=False,\n",
    "        font=dict(color=\"rgb(31,119,180)\", size=14),\n",
    "        bgcolor=\"rgba(255,255,255,0.7)\",\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        **p_train\n",
    "    )\n",
    "\n",
    "    # Place test AUC\n",
    "    p_test = pos_for_auc(auc_test)\n",
    "    # shift slightly if they collide\n",
    "    if p_test == p_train:\n",
    "        # if both on same corner, offset the test one inward\n",
    "        p_test['x'] -= 0.0 if p_test['xanchor']==\"right\" else -0.0\n",
    "        p_test['y'] += 0.07 if p_test['yanchor']==\"bottom\" else -0.07\n",
    "\n",
    "    fig.add_annotation(\n",
    "        text=f\"<b>Test AUC:</b> {auc_test:.2f}\",\n",
    "        showarrow=False,\n",
    "        font=dict(color=\"rgb(255,127,14)\", size=14),\n",
    "        bgcolor=\"rgba(255,255,255,0.7)\",\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        **p_test\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            \"text\": \"Train vs. Test ROC Curves\",\n",
    "            \"x\": 0.5, \"xanchor\": \"center\"\n",
    "        },\n",
    "        title_x=0.5,\n",
    "        xaxis_title=\"False Positive Rate (1 – Specificity)\",\n",
    "        yaxis_title=\"True Positive Rate (Recall)\",\n",
    "        xaxis=dict(range=[0,1], showgrid=True),\n",
    "        yaxis=dict(range=[0,1], showgrid=True),\n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\",\n",
    "        width=700, height=600\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43ac812",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve_area(train_eval_df, test_eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9baa6ab",
   "metadata": {},
   "source": [
    "## Plot 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42670bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_reference_pr_curves():\n",
    "    p = np.linspace(0, 1, 200)\n",
    "    perfect_r = np.where(p < 1, 1.0, 0.0)\n",
    "    L = 0.5\n",
    "    good_r = 1 - (1 - L)*p**4     # = 1 - 0.75*p**2 → at p=0 → 1, at p=1 → 0.25\n",
    "    auc_good  = np.trapz(good_r, p)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # ---- Three colored zones (layer='below') ----\n",
    "    # 1) Above 0.5 → light green\n",
    "    fig.add_shape(dict(\n",
    "        type=\"rect\",\n",
    "        xref=\"paper\", x0=0, x1=1,\n",
    "        yref=\"y\",     y0=0.5, y1=1,\n",
    "        fillcolor=\"rgba(0,255,0,0.2)\",\n",
    "        line=dict(width=0),\n",
    "        layer=\"below\"\n",
    "    ))\n",
    "    # 2) Middle band 0.25–0.5 → light red\n",
    "    fig.add_shape(dict(\n",
    "        type=\"rect\",\n",
    "        xref=\"paper\", x0=0, x1=1,\n",
    "        yref=\"y\",     y0=0.25, y1=0.5,\n",
    "        fillcolor=\"rgba(255,0,0,0.1)\",\n",
    "        line=dict(width=0),\n",
    "        layer=\"below\"\n",
    "    ))\n",
    "    # 3) Below 0.25 → darker red\n",
    "    fig.add_shape(dict(\n",
    "        type=\"rect\",\n",
    "        xref=\"paper\", x0=0, x1=1,\n",
    "        yref=\"y\",     y0=0, y1=0.25,\n",
    "        fillcolor=\"rgba(255,0,0,0.3)\",\n",
    "        line=dict(width=0),\n",
    "        layer=\"below\"\n",
    "    ))\n",
    "\n",
    "    # ---- Dashed baseline lines (layer='above') ----\n",
    "    fig.add_shape(type=\"line\",\n",
    "        x0=0, y0=0.5, x1=1, y1=0.5,\n",
    "        line=dict(dash=\"dash\", color=\"black\"),\n",
    "        layer=\"above\"\n",
    "    )\n",
    "    fig.add_shape(type=\"line\",\n",
    "        x0=0, y0=0.25, x1=1, y1=0.25,\n",
    "        line=dict(dash=\"dash\", color=\"black\"),\n",
    "        layer=\"above\"\n",
    "    )\n",
    "\n",
    "    # ---- PR curves ----\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=p, y=perfect_r, mode=\"lines\",\n",
    "        line=dict(color=\"Green\", width=3),\n",
    "        showlegend=False\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=p, y=good_r, mode=\"lines\",\n",
    "        line=dict(color=\"blue\", width=3,\n",
    "                  shape=\"spline\", smoothing=1.2),\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    # ---- On‐curve labels ----\n",
    "    fig.add_annotation(\n",
    "        x=0.85, y=0.95, text=\"AP = 1.00 (Perfect)\",\n",
    "        font=dict(color=\"Green\", size=14),\n",
    "        showarrow=False,\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=0.75, y=0.7, \n",
    "        text=f\"AP ≈ {auc_good:.2f} (Good)\",\n",
    "        font=dict(color=\"blue\", size=14),\n",
    "        showarrow=False,\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=0.15, y=0.5, text=\"Baseline (P:N=1:1)\",\n",
    "        font=dict(color=\"black\", size=14),\n",
    "        showarrow=False, yshift=10\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=0.15, y=0.25, text=\"Baseline (P:N=1:3)\",\n",
    "        font=dict(color=\"black\", size=14),\n",
    "        showarrow=False, yshift=10\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=0.75, y=0.35, text=\"Poor (P:N=1:1)\",\n",
    "        font=dict(color=\"rgba(255,0,0,0.5)\", size=14),\n",
    "        showarrow=False, yshift=10\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=0.75, y=0.15, text=\"Poor (P:N=1:3)\",\n",
    "        font=dict(color=\"rgba(255,0,0,0.7)\", size=14),\n",
    "        showarrow=False, yshift=10\n",
    "    )\n",
    "    # ---- Axis styling (no grid lines) ----\n",
    "    fig.update_xaxes(\n",
    "        title=\"Recall\",\n",
    "        range=[0,1],\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        showline=True,\n",
    "        linecolor=\"black\",\n",
    "        linewidth=2\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title=\"Precision\",\n",
    "        range=[0,1],\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        showline=True,\n",
    "        linecolor=\"black\",\n",
    "        linewidth=2\n",
    "    )\n",
    "\n",
    "    # ---- Final layout ----\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            \"text\": \"Reference PR Curve\",\n",
    "            \"x\": 0.5, \"xanchor\": \"center\"\n",
    "        },\n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\",\n",
    "        width=700, height=600\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Usage:\n",
    "# fig = plot_reference_pr_curves()\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4e73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reference_pr_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60889dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "def plot_pr_curve_area(train_eval_df: pd.DataFrame,\n",
    "                       test_eval_df: pd.DataFrame) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Overlay smooth Precision–Recall areas for train and test,\n",
    "    hide their own legend entries, place the Average Precision (AP)\n",
    "    and also draw horizontal baseline lines at P/(P+N) for each set,\n",
    "    labeling them with the P:N ratio.\n",
    "    \"\"\"\n",
    "    def prepare(dfm: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Expects dfm to have columns: \n",
    "        ['threshold','TN','FP','FN','TP','precision','recall']\n",
    "        Returns:\n",
    "        dfc, ap_val, baseline, pn_ratio\n",
    "        \"\"\"\n",
    "        # 1) Compute P and N once (they're constant over thresholds)\n",
    "        #    We can take the first row, or filter threshold==0 if you prefer.\n",
    "        first = dfm.iloc[0]\n",
    "        P = first.TP + first.FN\n",
    "        N = first.TN + first.FP\n",
    "\n",
    "        # 2) Baseline precision = P / (P + N)\n",
    "        baseline   = P / (P + N)\n",
    "\n",
    "        # 3) P:N ratio\n",
    "        pn_ratio   = P / N\n",
    "\n",
    "        # 4) Build a PR table\n",
    "        dfc = dfm[[\"threshold\", \"recall\", \"precision\"]].copy()\n",
    "\n",
    "        # 5) Prepend the (0,1) endpoint if you like\n",
    "        endpoint = pd.DataFrame({\n",
    "            \"threshold\": [1.0],\n",
    "            \"recall\":    [0.0],\n",
    "            \"precision\": [1.0]\n",
    "        })\n",
    "        dfc = pd.concat([dfc, endpoint], ignore_index=True) \\\n",
    "            .drop_duplicates(\"threshold\", keep=\"last\") \\\n",
    "            .sort_values(\"recall\") \\\n",
    "            .reset_index(drop=True)\n",
    "\n",
    "        # 6) Compute Average Precision via trapezoid\n",
    "        ap_val = np.trapz(dfc[\"precision\"], dfc[\"recall\"])\n",
    "\n",
    "        return dfc, ap_val, baseline, pn_ratio\n",
    "\n",
    "    def corner_for_ap(ap: float):\n",
    "        # Choose annotation corner\n",
    "        if ap > 0.5:\n",
    "            return dict(x=0.4, y=0.05, xanchor=\"left\",  yanchor=\"bottom\")\n",
    "        else:\n",
    "            return dict(x=0.75, y=0.95, xanchor=\"right\",   yanchor=\"top\")\n",
    "\n",
    "    # Prepare train and test\n",
    "    df_train, ap_train, base_train, pn_train = prepare(train_eval_df)\n",
    "    df_test,  ap_test,  base_test,  pn_test  = prepare(test_eval_df)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # --- Train PR curve (no legend) ---\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_train[\"recall\"], y=df_train[\"precision\"],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"rgb(31,119,180)\", shape=\"spline\", smoothing=1.3),\n",
    "        fill=\"tozeroy\", fillcolor=\"rgba(31,119,180,0.2)\",\n",
    "        marker=dict(size=6),\n",
    "        showlegend=False,\n",
    "        hovertemplate=(\n",
    "            \"Train PR<br>\"\n",
    "            \"Threshold %{text}<br>\"\n",
    "            \"Recall = %{x:.2f}<br>\"\n",
    "            \"Precision = %{y:.2f}<extra></extra>\"\n",
    "        ),\n",
    "        text=[f\"{t:.2f}\" for t in df_train[\"threshold\"]]\n",
    "    ))\n",
    "\n",
    "    # --- Test PR curve (no legend) ---\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_test[\"recall\"], y=df_test[\"precision\"],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"rgb(255,127,14)\", shape=\"spline\", smoothing=1.3),\n",
    "        fill=\"tozeroy\", fillcolor=\"rgba(255,127,14,0.2)\",\n",
    "        marker=dict(size=6),\n",
    "        showlegend=False,\n",
    "        hovertemplate=(\n",
    "            \"Test PR<br>\"\n",
    "            \"Threshold %{text}<br>\"\n",
    "            \"Recall = %{x:.2f}<br>\"\n",
    "            \"Precision = %{y:.2f}<extra></extra>\"\n",
    "        ),\n",
    "        text=[f\"{t:.2f}\" for t in df_test[\"threshold\"]]\n",
    "    ))\n",
    "\n",
    "    # --- Baseline lines (with legend entries) ---\n",
    "    # Train baseline\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[0, 1], y=[base_train, base_train],\n",
    "        mode=\"lines\",\n",
    "        line=dict(dash=\"dot\", color=\"rgb(31,119,180)\", width=2),\n",
    "        name=f\"Train baseline (P:N≈{pn_train:.2f}:1)\",\n",
    "        showlegend=False,\n",
    "    ))\n",
    "    # Test baseline\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[0, 1], y=[base_test,  base_test],\n",
    "        mode=\"lines\",\n",
    "        line=dict(dash=\"dash\", color=\"rgb(255,127,14)\", width=2),\n",
    "        name=f\"Test baseline (P:N≈{pn_test:.2f}:1)\",\n",
    "        showlegend=False,\n",
    "    ))\n",
    "\n",
    "    # ---- AUC annotations (corner) ----\n",
    "    p_train = corner_for_ap(ap_train)\n",
    "    fig.add_annotation(\n",
    "        text=f\"<b>Train AP:</b> {ap_train:.2f}\",\n",
    "        showarrow=False,\n",
    "        font=dict(color=\"rgb(31,119,180)\", size=14),\n",
    "        bgcolor=\"rgba(255,255,255,0.7)\",\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        **p_train\n",
    "    )\n",
    "\n",
    "    p_test = corner_for_ap(ap_test)\n",
    "    # if they’d collide, shift only the TEST one vertically:\n",
    "    if p_test == p_train:\n",
    "        p_test[\"y\"] += 0.07 if p_test[\"yanchor\"]==\"bottom\" else -0.07\n",
    "\n",
    "    fig.add_annotation(\n",
    "        text=f\"<b>Test AP:</b> {ap_test:.2f}\",\n",
    "        showarrow=False,\n",
    "        font=dict(color=\"rgb(255,127,14)\", size=14),\n",
    "        bgcolor=\"rgba(255,255,255,0.7)\",\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        **p_test\n",
    "    )\n",
    "\n",
    "    # ---- Baseline annotations (at end of line) ----\n",
    "    fig.add_annotation(\n",
    "        x=0.3, y=base_train - 0.05,\n",
    "        xref=\"x\", yref=\"y\",\n",
    "        text=f\"Train baseline (P:N≈{pn_train:.1f}:1.0)\",\n",
    "        showarrow=False,\n",
    "        font=dict(color=\"rgb(31,119,180)\", size=12),\n",
    "        xanchor=\"right\", yanchor=\"middle\",\n",
    "        # bgcolor=\"rgba(255,255,255,0.7)\"\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=1, y=base_test+0.05,\n",
    "        xref=\"x\", yref=\"y\",\n",
    "        text=f\"Test baseline (P:N≈{pn_test:.1f}:1.0)\",\n",
    "        showarrow=False,\n",
    "        font=dict(color=\"rgb(255,127,14)\", size=12),\n",
    "        xanchor=\"right\", yanchor=\"middle\",\n",
    "        # bgcolor=\"rgba(255,255,255,0.7)\"\n",
    "    )\n",
    "\n",
    "    # --- Layout ---\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            \"text\": \"Train vs. Test Precision–Recall Curves\",\n",
    "            \"x\": 0.5, \"xanchor\": \"center\"\n",
    "        },\n",
    "        title_x=0.5,\n",
    "        xaxis_title=\"Recall\",\n",
    "        yaxis_title=\"Precision\",\n",
    "        xaxis=dict(range=[0,1], showgrid=True),\n",
    "        yaxis=dict(range=[0,1], showgrid=True),\n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\",\n",
    "        width=750, height=600\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c706f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_curve_area(train_eval_df, test_eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1936ef1",
   "metadata": {},
   "source": [
    "## Plot 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b13101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_decision_threshold_slider(\n",
    "    dfm: pd.DataFrame,\n",
    "    metrics: list = [\"precision\", \"recall\", \"f1\", \"accuracy\", \"specificity\"],\n",
    "    default_threshold: float = 0.5\n",
    ") -> go.Figure:\n",
    "    \"\"\"\n",
    "    Plot several metrics vs. threshold with a slider.\n",
    "    Only precision & recall are shown initially; the rest start as 'legendonly'.\n",
    "    Legend‐click will toggle any curve on/off.\n",
    "    \"\"\"\n",
    "    # 1) Sort and find default index\n",
    "    df = dfm.sort_values(\"threshold\").reset_index(drop=True)\n",
    "    if default_threshold in df[\"threshold\"].values:\n",
    "        default_idx = int(df.index[df[\"threshold\"] == default_threshold][0])\n",
    "    else:\n",
    "        default_idx = 0\n",
    "\n",
    "    # 2) Create the figure and metric traces\n",
    "    colors = {\n",
    "        \"precision\":   \"blue\",\n",
    "        \"recall\":      \"red\",\n",
    "        \"f1\":          \"green\",\n",
    "        \"accuracy\":    \"purple\",\n",
    "        \"specificity\": \"orange\"\n",
    "    }\n",
    "    # Only these two should be visible at start:\n",
    "    default_on = {\"precision\", \"recall\"}\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for metric in metrics:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df[\"threshold\"],\n",
    "            y=df[metric],\n",
    "            mode=\"lines\",\n",
    "            name=metric.capitalize(),\n",
    "            line=dict(color=colors[metric], shape=\"spline\", smoothing=1.3),\n",
    "            marker=dict(size=6),\n",
    "            visible=True if metric in default_on else \"legendonly\",\n",
    "            legendgroup=metric.capitalize()\n",
    "        ))\n",
    "\n",
    "    # 3) Vertical threshold line\n",
    "    t0 = df.loc[default_idx, \"threshold\"]\n",
    "    fig.add_shape(dict(\n",
    "        type=\"line\", x0=t0, x1=t0, y0=0, y1=1,\n",
    "        xref=\"x\", yref=\"paper\",\n",
    "        line=dict(dash=\"dot\", color=\"black\", width=2)\n",
    "    ))\n",
    "\n",
    "    # 4) Single annotation outside the plot\n",
    "    def make_text(idx):\n",
    "        lines = []\n",
    "        for m in metrics:\n",
    "            val = df.loc[idx, m]\n",
    "            lines.append(f\"<b>{m.capitalize()}:</b> {val:.2f}\")\n",
    "        return \"<br>\".join(lines)\n",
    "\n",
    "    fig.update_layout(\n",
    "        annotations=[dict(\n",
    "            x=1.02, y=0.02, xref=\"paper\", yref=\"paper\",\n",
    "            text=make_text(default_idx),\n",
    "            showarrow=False, align=\"left\",\n",
    "            font=dict(size=14),\n",
    "            bgcolor=\"white\",\n",
    "            bordercolor=\"black\",\n",
    "            borderwidth=1,\n",
    "            opacity=0.8\n",
    "        )],\n",
    "        margin=dict(l=60, r=160, t=80, b=80)\n",
    "    )\n",
    "\n",
    "    # 5) Slider steps: update line + annotation\n",
    "    steps = []\n",
    "    for i, row in df.iterrows():\n",
    "        t = row[\"threshold\"]\n",
    "        args = {\n",
    "            \"shapes[0].x0\": t,\n",
    "            \"shapes[0].x1\": t,\n",
    "            \"annotations[0].text\": make_text(i)\n",
    "        }\n",
    "        steps.append(dict(\n",
    "            method=\"relayout\",\n",
    "            label=f\"{t:.2f}\",\n",
    "            args=[args]\n",
    "        ))\n",
    "\n",
    "    slider = {\n",
    "        \"active\": default_idx,\n",
    "        \"pad\": {\"t\": 50},\n",
    "        \"len\": 0.8,\n",
    "        \"x\": 0.1,\n",
    "        \"steps\": steps,\n",
    "        \"currentvalue\": {\n",
    "            \"visible\": True,\n",
    "            \"prefix\": \"Threshold: \",\n",
    "            \"xanchor\": \"center\",\n",
    "            \"font\": {\"size\": 14, \"color\": \"black\"},\n",
    "        },\n",
    "        # hide every tick-mark\n",
    "        \"ticklen\":   0,\n",
    "        \"tickwidth\": 0,\n",
    "        \"tickcolor\": \"rgba(0,0,0,0)\",\n",
    "        \"font\": {\"color\": \"rgba(0,0,0,0)\"},  # still hide the labels\n",
    "        \"bgcolor\": \"white\",\n",
    "        \"bordercolor\": \"lightgray\",\n",
    "    }\n",
    "\n",
    "    # 6) Final layout\n",
    "    fig.update_layout(\n",
    "        sliders=[slider],\n",
    "        title=\"Decision Threshold Metrics\\n(Precision & Recall shown by default)\",\n",
    "        xaxis=dict(\n",
    "            title=\"Threshold\", range=[0,1], dtick=0.1,\n",
    "            showgrid=True, gridcolor=\"lightgray\"\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"Metric Value\", range=[0,1], dtick=0.1,\n",
    "            showgrid=True, gridcolor=\"lightgray\"\n",
    "        ),\n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\",\n",
    "        width=900, height=600,\n",
    "        legend=dict(\n",
    "            itemclick=\"toggle\",           # click to show/hide each trace\n",
    "            itemdoubleclick=\"toggleothers\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aec616",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_threshold_slider(train_eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613d2353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_gain_lift_plotly(\n",
    "    data: pd.DataFrame,\n",
    "    actual: str = \"actual\",\n",
    "    probability: str = \"probability\",\n",
    "    bins: int = 10\n",
    ") -> go.Figure:\n",
    "    \"\"\"\n",
    "    Plot interactive Gain and Lift charts with Plotly, including baseline annotations.\n",
    "    \"\"\"\n",
    "    # Prepare and bucket the data\n",
    "    df = data[[actual, probability]].copy()\n",
    "    df = df.sort_values(by=probability, ascending=False).reset_index(drop=True)\n",
    "    df[\"bucket\"] = pd.qcut(df.index, q=bins, labels=False)\n",
    "\n",
    "    # Compute bucket stats\n",
    "    total_pos = df[actual].sum()\n",
    "    stats = (\n",
    "        df.groupby(\"bucket\")[actual]\n",
    "          .agg(bucket_positives=\"sum\", bucket_size=\"count\")\n",
    "          .sort_index()\n",
    "    )\n",
    "    stats[\"cum_positives\"] = stats[\"bucket_positives\"].cumsum()\n",
    "    stats[\"gain\"] = stats[\"cum_positives\"] / total_pos\n",
    "    stats[\"pop_pct\"] = (stats.index + 1) / bins\n",
    "    stats[\"lift\"] = stats[\"gain\"] / stats[\"pop_pct\"]\n",
    "\n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=(\"Gain Chart\", \"Lift Chart\"),\n",
    "        horizontal_spacing=0.15\n",
    "    )\n",
    "\n",
    "    # Gain chart: model vs. random baseline\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=stats[\"pop_pct\"],\n",
    "            y=stats[\"gain\"],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Model Gain\",\n",
    "            hovertemplate=\"Population: %{x:.0%}<br>Gain: %{y:.0%}<extra></extra>\"\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0, 1],\n",
    "            y=[0, 1],\n",
    "            mode=\"lines\",\n",
    "            name=\"Random Baseline\",\n",
    "            line=dict(dash=\"dash\", color=\"gray\"),\n",
    "            hoverinfo=\"skip\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    # Annotation for the random baseline\n",
    "    fig.add_annotation(\n",
    "        x=0.55, y=0.5,\n",
    "        xref=\"x1\", yref=\"y1\",\n",
    "        text=\"Baseline(Random model)\",\n",
    "        showarrow=False,\n",
    "        font=dict(color=\"gray\", size=12),\n",
    "        textangle=-43\n",
    "    )\n",
    "\n",
    "    # Lift chart: model vs. lift=1 baseline\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=stats[\"pop_pct\"],\n",
    "            y=stats[\"lift\"],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Model Lift\",\n",
    "            hovertemplate=\"Population: %{x:.0%}<br>Lift: %{y:.2f}<extra></extra>\"\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0, 1],\n",
    "            y=[1, 1],\n",
    "            mode=\"lines\",\n",
    "            name=\"Lift = 1\",\n",
    "            line=dict(dash=\"dash\", color=\"gray\"),\n",
    "            hoverinfo=\"skip\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    # Annotation for the lift=1 baseline\n",
    "    fig.add_annotation(\n",
    "        x=0.5, y=1.05,\n",
    "        xref=\"x2\", yref=\"y2\",\n",
    "        text=\"Baseline (Lift=1)\",\n",
    "        showarrow=False,\n",
    "        font=dict(color=\"gray\", size=12)\n",
    "    )\n",
    "\n",
    "    # Axes & layout\n",
    "    fig.update_xaxes(title=\"Cumulative Population %\", tickformat=\".0%\", row=1, col=1)\n",
    "    fig.update_yaxes(title=\"Cumulative Positives %\", tickformat=\".0%\", row=1, col=1)\n",
    "    fig.update_xaxes(title=\"Cumulative Population %\", tickformat=\".0%\", row=1, col=2)\n",
    "    fig.update_yaxes(title=\"Lift (Gain / Cum. Pop. %)\", row=1, col=2)\n",
    "\n",
    "    fig.update_layout(\n",
    "        legend=dict(x=0.35, y=1.15, orientation=\"h\"),\n",
    "        width=900, height=500,\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b15303",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gain_lift_plotly(train_df, actual=\"actual\", probability=\"probability\", bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d7a35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f66e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
